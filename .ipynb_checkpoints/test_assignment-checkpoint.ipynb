{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json('test.json')\n",
    "train_df = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        italian\n",
       "1          greek\n",
       "2        italian\n",
       "3    southern_us\n",
       "4         french\n",
       "Name: cuisine, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=train_df['cuisine']\n",
    "train=train_df.drop('cuisine',axis=1)\n",
    "test=test_df\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()\n",
    "t.fit_on_texts(train['ingredients'])\n",
    "train_encoded=t.texts_to_matrix(train['ingredients'],mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines=train_df['cuisine'].unique()\n",
    "label2index={cuisine:i for i,cuisine in enumerate(cuisines)}\n",
    "y=[]\n",
    "\n",
    "for item in target:\n",
    "    if item in label2index.keys():\n",
    "        y.append(label2index[item])\n",
    "y_encoded=to_categorical(y,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29774, 6189)\n",
      "(29774, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_encoded.shape)\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(256,input_shape=[train_encoded.shape[1], ],activation='relu',name='hidden_1'))\n",
    "    model.add(Dropout(0.4, name='dropout_1'))\n",
    "    \n",
    "    #model.add(Dense(64,activation='relu',name='hidden_2'))\n",
    "    #model.add(Dropout(0.2,name='dropout_2'))\n",
    "    \n",
    "    model.add(Dense(20,name='output'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_hinge',\n",
    "                  metrics=['accuracy']\n",
    "                )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train_encoded,y_encoded,test_size=0.2,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 256)               1584640   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 1,589,780\n",
      "Trainable params: 1,589,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23819 samples, validate on 5955 samples\n",
      "Epoch 1/100\n",
      "23819/23819 [==============================] - 6s 264us/step - loss: 0.7442 - acc: 0.6360 - val_loss: 0.5301 - val_acc: 0.7594\n",
      "Epoch 2/100\n",
      "23819/23819 [==============================] - 5s 220us/step - loss: 0.4138 - acc: 0.8241 - val_loss: 0.5095 - val_acc: 0.7741\n",
      "Epoch 3/100\n",
      "23819/23819 [==============================] - 5s 220us/step - loss: 0.2962 - acc: 0.8818 - val_loss: 0.5144 - val_acc: 0.7746\n",
      "Epoch 4/100\n",
      "23819/23819 [==============================] - 5s 226us/step - loss: 0.2251 - acc: 0.9133 - val_loss: 0.5325 - val_acc: 0.7745\n",
      "Epoch 5/100\n",
      "23819/23819 [==============================] - 6s 233us/step - loss: 0.1798 - acc: 0.9330 - val_loss: 0.5452 - val_acc: 0.7735\n",
      "Epoch 6/100\n",
      "23819/23819 [==============================] - 5s 224us/step - loss: 0.1468 - acc: 0.9466 - val_loss: 0.5589 - val_acc: 0.7718\n",
      "Epoch 7/100\n",
      "23819/23819 [==============================] - 5s 223us/step - loss: 0.1256 - acc: 0.9548 - val_loss: 0.5723 - val_acc: 0.7760\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2f0f8cf8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor=[\n",
    "    EarlyStopping(monitor='val_loss',patience=5,verbose=1),\n",
    "    ModelCheckpoint('best-model-0.h5',monitor='val_loss',save_best_only=True,save_weights_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "         validation_data=(X_val,y_val),\n",
    "         epochs=100,\n",
    "         callbacks=monitor,\n",
    "         batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoded=t.texts_to_matrix(test_df['ingredients'],mode='tfidf')\n",
    "test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['korean',\n",
       " 'italian',\n",
       " 'italian',\n",
       " 'filipino',\n",
       " 'italian',\n",
       " 'cajun_creole',\n",
       " 'italian',\n",
       " 'thai',\n",
       " 'chinese',\n",
       " 'southern_us']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best-model-0.h5')\n",
    "y_pred=model.predict(test_encoded).argmax(axis=1)\n",
    "\n",
    "results=[]\n",
    "\n",
    "for i in y_pred:\n",
    "    for k,v in label2index.items():\n",
    "        if v==i:\n",
    "            results.append(k)\n",
    "\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame(list(zip(test_df['id'],results)),columns=['id','cuisine'])\n",
    "submission.to_csv('submission.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
